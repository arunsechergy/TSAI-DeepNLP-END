{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NextSteps_Tokenize_Python_code_generate_predictions_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjFLRqe+sREUm7jTVkgV6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunsechergy/TSAI-DeepNLP-END/blob/main/assignments/assignment14/NextSteps_Tokenize_Python_code_generate_predictions_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_0OJT3zpORb"
      },
      "source": [
        "Analysis:\r\n",
        "1. Model is able to generate python code\r\n",
        "2. Understands indendation and newline, colon\r\n",
        "3. Inaccurate python code, need more understanding on the logic to be written\r\n",
        "4. need better examples\r\n",
        "5. need complete results\r\n",
        "\r\n",
        "Current steps:\r\n",
        "1. Increase number of epochs for learning (if needed, tweak learning rate)\r\n",
        "2. Increase Max Sequence length as well\r\n",
        "- Decrease the split\r\n",
        "2. Add Data Augmentation strategy\r\n",
        "3. Any other loss function, needs to be checked \r\n",
        "4. Add Pretrained Python embedding layer\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o2pKxe5Xuc6"
      },
      "source": [
        "file = 'drive/MyDrive/datasets/english_python_data_tabs.txt'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpVKHOoDX7-7"
      },
      "source": [
        "mkdir data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9kcCMFBYBQM",
        "outputId": "557e13a9-c2c9-4033-d7ff-86d04c8a8335"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvEyA-GNXvJ1"
      },
      "source": [
        "!cp -r  'drive/MyDrive/datasets/english_python_data_tabs.txt' 'data/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF6WBdkzXFIj"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import torchtext\r\n",
        "#from torchtext.data import Field, BucketIterator\r\n",
        "from torchtext.legacy.data import Example, Field, BucketIterator, Dataset\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvf-W2iuXlsX"
      },
      "source": [
        "import tokenize\r\n",
        "import os\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "from io import BytesIO, StringIO"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjAJXxWlXmpK"
      },
      "source": [
        "DATA_DIR = 'data'\r\n",
        "corpus_name = \"english_python_data_tabs.txt\"\r\n",
        "# corpus_name = \"english_python_data.txt\"\r\n",
        "corpus = os.path.join(DATA_DIR, corpus_name)\r\n",
        "\r\n",
        "def readLines(file, n=None):\r\n",
        "    with open(file, 'r') as datafile:\r\n",
        "        lines = datafile.readlines()\r\n",
        "    return lines\r\n",
        "    # n = len(lines) if n is None else n\r\n",
        "    # for line in lines[:n]:\r\n",
        "    #     print(line)\r\n",
        "\r\n",
        "input_file= readLines(corpus)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3nrTjGZYM31"
      },
      "source": [
        "q_c = {}\r\n",
        "prev_value = []\r\n",
        "for id, line in enumerate(input_file):\r\n",
        "  #if line.startswith('#'):\r\n",
        "  #if (line.lower().startswith('# write'))  or (line.lower().startswith('#write')) or (line.lower().startswith('#python')) or (line.lower().startswith('# python')):\r\n",
        "  if re.match(r'[#]\\d*\\s*(Write|write|python|Python)', line):  \r\n",
        "    q_c[line] = id\r\n",
        "    prev_line = line\r\n",
        "    prev_value = []\r\n",
        "  else:\r\n",
        "    prev_value.append(line)\r\n",
        "    q_c[prev_line] = prev_value"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jrx9xCxYTW9"
      },
      "source": [
        "question_code_pairs = pd.DataFrame.from_dict(q_c.items())\r\n",
        "question_code_pairs.columns = ['question', 'code']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdr4-JT8YZ_5"
      },
      "source": [
        "question_code_pairs['code'] = question_code_pairs['code'].apply(lambda x: \"\".join(x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-ulu10KYbye"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfk7mm9LYeFZ"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfJ4xWk9ewL"
      },
      "source": [
        "#CONSTANT DEFINITION\r\n",
        "MAX_SEQ_LENGTH = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmp3ryrXYhnQ"
      },
      "source": [
        "def tokenize_en(text, max_length=MAX_SEQ_LENGTH):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    tokens = [tok.text for tok in spacy_en.tokenizer(text)]\r\n",
        "    tokens = tokens[:max_length]\r\n",
        "    return tokens"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnlMQA9PYoRL"
      },
      "source": [
        "def tokenize_py(text, max_length=MAX_SEQ_LENGTH):\r\n",
        "  \"\"\"\r\n",
        "  Tokenizes Python code from a string into a list of strings\r\n",
        "  \"\"\"\r\n",
        "  tokenized_code = []\r\n",
        "  tokens = tokenize.tokenize(BytesIO(text.encode('utf-8')).readline)\r\n",
        "  try:\r\n",
        "    for token in tokens:\r\n",
        "      tokenized_code.append(token.string)\r\n",
        "    # tokens = [token.string for token in tokens]\r\n",
        "  except Exception as e:\r\n",
        "    pass\r\n",
        "    # print(f\"Error in tokenization {e}\")\r\n",
        "\r\n",
        "  tokens = tokenized_code[:max_length]\r\n",
        "  return tokens"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vGXTBGiYkTT"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "TRG = Field(tokenize = tokenize_py, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True\r\n",
        "            )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGub3FhkbAbz"
      },
      "source": [
        "fields = [('src', SRC), ('trg', TRG)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RitJggaGbuvY",
        "outputId": "e2e2ec7a-ada1-4be6-ae8d-5b5a43a905a9"
      },
      "source": [
        "train_len = int(0.95*(question_code_pairs.shape[0]))\r\n",
        "valid_len = int(0.98*(question_code_pairs.shape[0]))\r\n",
        "test_len = int((question_code_pairs.shape[0]))\r\n",
        "\r\n",
        "train_len, valid_len, test_len"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1921, 2028, 2135)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm3JdopMFLDb"
      },
      "source": [
        "train_pair, valid_pair, test_pair = question_code_pairs[:train_len], question_code_pairs[train_len:valid_len], question_code_pairs[valid_len:test_len]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYT9jLRfFVFB"
      },
      "source": [
        "train_example = [Example.fromlist([train_pair.question[i], train_pair.code[i]], fields) for i in range(train_len)]\r\n",
        "train_data = Dataset(train_example, fields)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbPNYRNkGkJm"
      },
      "source": [
        "valid_example = [Example.fromlist([valid_pair.question[i], valid_pair.code[i]], fields) for i in range(train_len, valid_len)]\r\n",
        "valid_data = Dataset(valid_example, fields)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ILNFqKKHS-w"
      },
      "source": [
        "test_example = [Example.fromlist([test_pair.question[i], test_pair.code[i]], fields) for i in range(valid_len, test_len)]\r\n",
        "test_data = Dataset(test_example, fields)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkU88cUzb3Z7"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6805ktkRfHmd",
        "outputId": "0e96879e-70c7-4e68-df98-8be64a736281"
      },
      "source": [
        "# checking :, \\t and \\n in the vocab\r\n",
        "vars(TRG.vocab)['stoi'].get(':'), vars(TRG.vocab)['stoi'].get('\\t'), vars(TRG.vocab)['stoi'].get('\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 14, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOrPFtp_fDPp",
        "outputId": "e0df708c-f23f-4d54-d3a0-73b7fa79e41e"
      },
      "source": [
        "# check max sequence length of the train_data\r\n",
        "len__ = []\r\n",
        "for i in range(len(train_data)):\r\n",
        "    len_ = len(vars(list(train_data)[i])['trg'])\r\n",
        "    len__.append(len_)\r\n",
        "max(len__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP5_46VOfRmy",
        "outputId": "e6733f34-8fa7-46cd-f777-f1db58e639e8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "device"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWrGxtof7_y"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "     batch_size = BATCH_SIZE,\r\n",
        "     device = device,sort=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df6b18Wnf-ds"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 input_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,\r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 100):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim,\r\n",
        "                                                  dropout, \r\n",
        "                                                  device) \r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        batch_size = src.shape[0]\r\n",
        "        src_len = src.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "        \r\n",
        "        #pos = [batch size, src len]\r\n",
        "\r\n",
        "        #print(f'{\"encoder pos Embedding\", self.pos_embedding(pos) }')\r\n",
        "        #print(f'{\"encoder pos Embedding shape\", pos.shape }')\r\n",
        "        \r\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            src = layer(src, src_mask)\r\n",
        "            \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "            \r\n",
        "        return src"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgjG5ziTgANi"
      },
      "source": [
        "class EncoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,  \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        #src_mask = [batch size, 1, 1, src len] \r\n",
        "                \r\n",
        "        #self attention\r\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _src = self.positionwise_feedforward(src)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        return src"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtZoYiSKgCUr"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert hid_dim % n_heads == 0\r\n",
        "        \r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_heads = n_heads\r\n",
        "        self.head_dim = hid_dim // n_heads\r\n",
        "        \r\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, query, key, value, mask = None):\r\n",
        "        \r\n",
        "        batch_size = query.shape[0]\r\n",
        "        \r\n",
        "        #query = [batch size, query len, hid dim]\r\n",
        "        #key = [batch size, key len, hid dim]\r\n",
        "        #value = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = self.fc_q(query)\r\n",
        "        K = self.fc_k(key)\r\n",
        "        V = self.fc_v(value)\r\n",
        "        \r\n",
        "        #Q = [batch size, query len, hid dim]\r\n",
        "        #K = [batch size, key len, hid dim]\r\n",
        "        #V = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        \r\n",
        "        #Q = [batch size, n heads, query len, head dim]\r\n",
        "        #K = [batch size, n heads, key len, head dim]\r\n",
        "        #V = [batch size, n heads, value len, head dim]\r\n",
        "                \r\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\r\n",
        "        \r\n",
        "        #energy = [batch size, n heads, query len, key len]\r\n",
        "        \r\n",
        "        if mask is not None:\r\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\r\n",
        "        \r\n",
        "        attention = torch.softmax(energy, dim = -1)\r\n",
        "                \r\n",
        "        #attention = [batch size, n heads, query len, key len]\r\n",
        "                \r\n",
        "        x = torch.matmul(self.dropout(attention), V)\r\n",
        "        \r\n",
        "        #x = [batch size, n heads, query len, head dim]\r\n",
        "        \r\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\r\n",
        "        \r\n",
        "        #x = [batch size, query len, n heads, head dim]\r\n",
        "        \r\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        x = self.fc_o(x)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        return x, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvBqmINjgD_t"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\r\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, pf dim]\r\n",
        "        \r\n",
        "        x = self.fc_2(x)\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mDXnIiKgGBq"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 output_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 100):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim, \r\n",
        "                                                  dropout, \r\n",
        "                                                  device)\r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "                \r\n",
        "        batch_size = trg.shape[0]\r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "                            \r\n",
        "        #pos = [batch size, trg len]\r\n",
        "        #print(f\"Shape of position: batch_size, trg_len {pos.shape} == {batch_size} {trg_len}\")\r\n",
        "\r\n",
        "        #print(f'{\"postion\", pos}')\r\n",
        "        #print(f'{\"token_embedding\",self.tok_embedding(trg)}')\r\n",
        "        #print(f'{\"self scale\", self.scale}')\r\n",
        "        #print(f'{\"self scale\", self.pos_embedding(pos)}')\r\n",
        "        #print(f'{\"print target\",(self.tok_embedding(trg) * self.scale)}')\r\n",
        "        #print(f'{\"print target\",(self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos)}')\r\n",
        "\r\n",
        "\r\n",
        "            \r\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\r\n",
        "                \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        output = self.fc_out(trg)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "            \r\n",
        "        return output, attention"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn7vhh_JgIJ6"
      },
      "source": [
        "class DecoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        #self attention\r\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "            \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "            \r\n",
        "        #encoder attention\r\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\r\n",
        "        # query, key, value\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "                    \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _trg = self.positionwise_feedforward(trg)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return trg, attention"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Ybe4-7gKXx"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 encoder, \r\n",
        "                 decoder, \r\n",
        "                 src_pad_idx, \r\n",
        "                 trg_pad_idx, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.src_pad_idx = src_pad_idx\r\n",
        "        self.trg_pad_idx = trg_pad_idx\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def make_src_mask(self, src):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        \r\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "\r\n",
        "        return src_mask\r\n",
        "    \r\n",
        "    def make_trg_mask(self, trg):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        \r\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "        \r\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
        "        \r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\r\n",
        "        \r\n",
        "        #trg_sub_mask = [trg len, trg len]\r\n",
        "            \r\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
        "        \r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        return trg_mask\r\n",
        "\r\n",
        "    def forward(self, src, trg):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "                \r\n",
        "        src_mask = self.make_src_mask(src)\r\n",
        "        trg_mask = self.make_trg_mask(trg)\r\n",
        "        \r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        enc_src = self.encoder(src, src_mask)\r\n",
        "        \r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "                \r\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return output, attention"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVLIub29gMWH"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "HID_DIM = 256\r\n",
        "ENC_LAYERS = 3\r\n",
        "DEC_LAYERS = 3\r\n",
        "ENC_HEADS = 8\r\n",
        "DEC_HEADS = 8\r\n",
        "ENC_PF_DIM = 512\r\n",
        "DEC_PF_DIM = 512\r\n",
        "ENC_DROPOUT = 0.1\r\n",
        "DEC_DROPOUT = 0.1\r\n",
        "MAX_SEQ_LENGTH = MAX_SEQ_LENGTH #this is defined earlier\r\n",
        "enc = Encoder(INPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              ENC_LAYERS, \r\n",
        "              ENC_HEADS, \r\n",
        "              ENC_PF_DIM, \r\n",
        "              ENC_DROPOUT, \r\n",
        "              device,\r\n",
        "              MAX_SEQ_LENGTH)\r\n",
        "\r\n",
        "dec = Decoder(OUTPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              DEC_LAYERS, \r\n",
        "              DEC_HEADS, \r\n",
        "              DEC_PF_DIM, \r\n",
        "              DEC_DROPOUT, \r\n",
        "              device,\r\n",
        "              MAX_SEQ_LENGTH)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI0lh9AsgUxw"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\r\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj0nes7jgWlN",
        "outputId": "8a6f5929-962c-4fa2-a6f1-a9d709f0a112"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,418,658 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohev4jAegX5v"
      },
      "source": [
        "def initialize_weights(m):\r\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\r\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyas1Hixgalq"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZDVKVKTgcR9"
      },
      "source": [
        "LEARNING_RATE = 0.0005\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njtD3l0PgdyF"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sy0KQnSgfWX"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.src\r\n",
        "        trg = batch.trg\r\n",
        "        #print(f'{\"traget\",trg}')\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output, _ = model(src, trg[:,:-1])\r\n",
        "        #print(output)\r\n",
        "                \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "        output = output.contiguous().view(-1, output_dim)\r\n",
        "        trg = trg[:,1:].contiguous().view(-1)\r\n",
        "                \r\n",
        "        #output = [batch size * trg len - 1, output dim]\r\n",
        "        #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMf3qwjKghPB"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.src\r\n",
        "            trg = batch.trg\r\n",
        "\r\n",
        "            output, _ = model(src, trg[:,:-1])\r\n",
        "            #print(output)\r\n",
        "            \r\n",
        "            #output = [batch size, trg len - 1, output dim]\r\n",
        "            #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output.contiguous().view(-1, output_dim)\r\n",
        "            trg = trg[:,1:].contiguous().view(-1)\r\n",
        "            \r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgn4pAMzgiyY"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_HFWcxIgkbV",
        "outputId": "64e87b46-6f78-41da-f2ac-6019ca5b20f5"
      },
      "source": [
        "# increased the num_of_epochs to 25\r\n",
        "N_EPOCHS = 25\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'python_code_generator1-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 3m 34s\n",
            "\tTrain Loss: 6.103 | Train PPL: 447.109\n",
            "\t Val. Loss: 4.878 |  Val. PPL: 131.366\n",
            "Epoch: 02 | Time: 3m 37s\n",
            "\tTrain Loss: 4.484 | Train PPL:  88.550\n",
            "\t Val. Loss: 3.658 |  Val. PPL:  38.802\n",
            "Epoch: 03 | Time: 3m 33s\n",
            "\tTrain Loss: 3.604 | Train PPL:  36.748\n",
            "\t Val. Loss: 3.076 |  Val. PPL:  21.679\n",
            "Epoch: 04 | Time: 3m 32s\n",
            "\tTrain Loss: 3.141 | Train PPL:  23.126\n",
            "\t Val. Loss: 2.777 |  Val. PPL:  16.067\n",
            "Epoch: 05 | Time: 3m 41s\n",
            "\tTrain Loss: 2.876 | Train PPL:  17.752\n",
            "\t Val. Loss: 2.599 |  Val. PPL:  13.455\n",
            "Epoch: 06 | Time: 3m 31s\n",
            "\tTrain Loss: 2.675 | Train PPL:  14.506\n",
            "\t Val. Loss: 2.477 |  Val. PPL:  11.901\n",
            "Epoch: 07 | Time: 3m 31s\n",
            "\tTrain Loss: 2.537 | Train PPL:  12.646\n",
            "\t Val. Loss: 2.376 |  Val. PPL:  10.756\n",
            "Epoch: 08 | Time: 3m 46s\n",
            "\tTrain Loss: 2.406 | Train PPL:  11.091\n",
            "\t Val. Loss: 2.268 |  Val. PPL:   9.658\n",
            "Epoch: 09 | Time: 3m 33s\n",
            "\tTrain Loss: 2.285 | Train PPL:   9.831\n",
            "\t Val. Loss: 2.202 |  Val. PPL:   9.044\n",
            "Epoch: 10 | Time: 3m 35s\n",
            "\tTrain Loss: 2.177 | Train PPL:   8.822\n",
            "\t Val. Loss: 2.161 |  Val. PPL:   8.684\n",
            "Epoch: 11 | Time: 3m 41s\n",
            "\tTrain Loss: 2.077 | Train PPL:   7.982\n",
            "\t Val. Loss: 2.101 |  Val. PPL:   8.173\n",
            "Epoch: 12 | Time: 3m 31s\n",
            "\tTrain Loss: 2.000 | Train PPL:   7.391\n",
            "\t Val. Loss: 2.091 |  Val. PPL:   8.096\n",
            "Epoch: 13 | Time: 3m 35s\n",
            "\tTrain Loss: 1.924 | Train PPL:   6.845\n",
            "\t Val. Loss: 2.031 |  Val. PPL:   7.624\n",
            "Epoch: 14 | Time: 3m 37s\n",
            "\tTrain Loss: 1.848 | Train PPL:   6.349\n",
            "\t Val. Loss: 2.003 |  Val. PPL:   7.411\n",
            "Epoch: 15 | Time: 3m 35s\n",
            "\tTrain Loss: 1.773 | Train PPL:   5.886\n",
            "\t Val. Loss: 1.966 |  Val. PPL:   7.142\n",
            "Epoch: 16 | Time: 3m 38s\n",
            "\tTrain Loss: 1.711 | Train PPL:   5.533\n",
            "\t Val. Loss: 1.947 |  Val. PPL:   7.009\n",
            "Epoch: 17 | Time: 3m 34s\n",
            "\tTrain Loss: 1.649 | Train PPL:   5.201\n",
            "\t Val. Loss: 1.943 |  Val. PPL:   6.980\n",
            "Epoch: 18 | Time: 3m 33s\n",
            "\tTrain Loss: 1.591 | Train PPL:   4.908\n",
            "\t Val. Loss: 1.938 |  Val. PPL:   6.944\n",
            "Epoch: 19 | Time: 3m 37s\n",
            "\tTrain Loss: 1.518 | Train PPL:   4.564\n",
            "\t Val. Loss: 1.904 |  Val. PPL:   6.712\n",
            "Epoch: 20 | Time: 3m 33s\n",
            "\tTrain Loss: 1.474 | Train PPL:   4.367\n",
            "\t Val. Loss: 1.907 |  Val. PPL:   6.731\n",
            "Epoch: 21 | Time: 3m 29s\n",
            "\tTrain Loss: 1.416 | Train PPL:   4.119\n",
            "\t Val. Loss: 1.911 |  Val. PPL:   6.762\n",
            "Epoch: 22 | Time: 3m 41s\n",
            "\tTrain Loss: 1.372 | Train PPL:   3.943\n",
            "\t Val. Loss: 1.880 |  Val. PPL:   6.553\n",
            "Epoch: 23 | Time: 3m 32s\n",
            "\tTrain Loss: 1.320 | Train PPL:   3.742\n",
            "\t Val. Loss: 1.899 |  Val. PPL:   6.681\n",
            "Epoch: 24 | Time: 3m 35s\n",
            "\tTrain Loss: 1.268 | Train PPL:   3.554\n",
            "\t Val. Loss: 1.894 |  Val. PPL:   6.643\n",
            "Epoch: 25 | Time: 3m 39s\n",
            "\tTrain Loss: 1.240 | Train PPL:   3.457\n",
            "\t Val. Loss: 1.865 |  Val. PPL:   6.459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG38U1aFgoJ5",
        "outputId": "4f8836aa-fdfa-4a7b-98d9-45db7517d546"
      },
      "source": [
        "model.load_state_dict(torch.load('python_code_generator1-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 2.125 | Test PPL:   8.374 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFjHEdpjopDV"
      },
      "source": [
        "#Save the model in drive\r\n",
        "!cp -r python_code_generator1-model.pt 'drive/MyDrive/Models/'"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHuwvBdNjTTP"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = MAX_SEQ_LENGTH):\r\n",
        "    # For Prediction\r\n",
        "  # Set the model in evaluation mode to deactivate the DropOut modules\r\n",
        "  # This is IMPORTANT to have reproducible results during evaluation!\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('en')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    src_mask = model.make_src_mask(src_tensor)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
        "\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKcRrudvk7H9"
      },
      "source": [
        "# Check the predictions"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmTfRBUtk6mn",
        "outputId": "69ee3ce4-b6ad-46c7-a585-b0012f16be53"
      },
      "source": [
        "example_idx = 1\r\n",
        "src = vars(test_data.examples[example_idx])['src']\r\n",
        "trg = vars(test_data.examples[example_idx])['trg']\r\n",
        "print(src)\r\n",
        "print(trg)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#', 'write', 'a', 'python', 'function', 'to', 'calculate', 'the', 'least', 'common', 'multiple', '(', 'lcm', ')', 'of', 'two', 'user', 'provided', 'positive', 'integers', '.']\n",
            "['utf-8', '\\n', 'def', 'lcm', '(', 'num1', ',', 'num2', ')', ':', '\\n', '\\t', 'if', 'num1', '>', 'num2', ':', '\\n', '\\t\\t', 'z', '=', 'num1', '\\n', '', 'else', ':', 'z', '=', 'num2', '\\n', 'while', '(', 'true', ')', ':', '\\n', '\\t\\t', 'if', '(', '(', 'z', '%', 'num1', '==', '0', ')', 'and', '(', 'z', '%', 'num2', '==', '0', ')', ')', ':', '\\n', '\\t\\t\\t', 'lcm', '=', 'z', '\\n', 'break', '\\n', '', 'z', '+=', '1', '\\n', '', 'return', 'lcm', '', '', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX6tUkECjWyu",
        "outputId": "4ec1ecb3-2247-4969-a261-646092d23514"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device, max_len=MAX_SEQ_LENGTH)\r\n",
        "processed_prediction = ' '.join(translation[1:-1]) # spaced joined, takes from 1 because of utf-8 token and ignore the eos token with -1\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "print(\"translated prediction\\n\", ' '.join(translation[1:-1]))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['utf-8', 'def', '<unk>', '(', 'x', ')', ':', '\\n', '\\t', 'if', 'x', '==', '0', ':', '\\n', '\\t\\t', 'return', '0', '\\n', '', 'else', ':', '\\n', '\\t\\t', 'return', 'false', '\\n', '\\n', '\\n', '', '', '', '', '<eos>']\n",
            "translated prediction\n",
            " def <unk> ( x ) : \n",
            " \t if x == 0 : \n",
            " \t\t return 0 \n",
            "  else : \n",
            " \t\t return false \n",
            " \n",
            " \n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzngNVAmmkk"
      },
      "source": [
        "# Evaluating the Generated Python code"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm6GEIu2lW2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "d19b0f5a-1080-40f7-e211-f751a317f42f"
      },
      "source": [
        "# replace the unk token with a name - test\r\n",
        "for_evaluation = processed_prediction.replace('<unk>', 'test')\r\n",
        "exec(for_evaluation)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    else :\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYzI2hOCmXJG"
      },
      "source": [
        "# If no error, then the run is successful"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah9MNmxBoDsm"
      },
      "source": [
        "# Attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EDnazsOm0q7"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\r\n",
        "    \r\n",
        "    assert n_rows * n_cols == n_heads\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(15,25))\r\n",
        "    \r\n",
        "    for i in range(n_heads):\r\n",
        "        \r\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\r\n",
        "        \r\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\r\n",
        "\r\n",
        "        cax = ax.matshow(_attention, cmap='bone')\r\n",
        "\r\n",
        "        ax.tick_params(labelsize=12)\r\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                           rotation=45)\r\n",
        "        ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}