{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenize_Python_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOC3YBMt2R+lDfVXYNlEYAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunsechergy/TSAI-DeepNLP-END/blob/main/assignments/assignment14/Tokenize_Python_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o2pKxe5Xuc6"
      },
      "source": [
        "file = 'drive/MyDrive/datasets/english_python_data_tabs.txt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpVKHOoDX7-7"
      },
      "source": [
        "mkdir data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9kcCMFBYBQM",
        "outputId": "b3bcecc9-263c-4e53-b721-3538d33d5f3e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvEyA-GNXvJ1"
      },
      "source": [
        "!cp -r  'drive/MyDrive/datasets/english_python_data_tabs.txt' 'data/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPMcUptXy58"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF6WBdkzXFIj"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import torchtext\r\n",
        "#from torchtext.data import Field, BucketIterator\r\n",
        "from torchtext.legacy.data import Example, Field, BucketIterator, Dataset\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvf-W2iuXlsX"
      },
      "source": [
        "import tokenize\r\n",
        "import os\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "from io import BytesIO"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjAJXxWlXmpK"
      },
      "source": [
        "DATA_DIR = 'data'\r\n",
        "corpus_name = \"english_python_data_tabs.txt\"\r\n",
        "# corpus_name = \"english_python_data.txt\"\r\n",
        "corpus = os.path.join(DATA_DIR, corpus_name)\r\n",
        "\r\n",
        "def readLines(file, n=None):\r\n",
        "    with open(file, 'r') as datafile:\r\n",
        "        lines = datafile.readlines()\r\n",
        "    return lines\r\n",
        "    # n = len(lines) if n is None else n\r\n",
        "    # for line in lines[:n]:\r\n",
        "    #     print(line)\r\n",
        "\r\n",
        "input_file= readLines(corpus)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3nrTjGZYM31"
      },
      "source": [
        "q_c = {}\r\n",
        "prev_value = []\r\n",
        "for id, line in enumerate(input_file):\r\n",
        "  #if line.startswith('#'):\r\n",
        "  #if (line.lower().startswith('# write'))  or (line.lower().startswith('#write')) or (line.lower().startswith('#python')) or (line.lower().startswith('# python')):\r\n",
        "  if re.match(r'[#]\\d*\\s*(Write|write|python|Python)', line):  \r\n",
        "    q_c[line] = id\r\n",
        "    prev_line = line\r\n",
        "    prev_value = []\r\n",
        "  else:\r\n",
        "    prev_value.append(line)\r\n",
        "    q_c[prev_line] = prev_value"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jrx9xCxYTW9"
      },
      "source": [
        "question_code_pairs = pd.DataFrame.from_dict(q_c.items())\r\n",
        "question_code_pairs.columns = ['question', 'code']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdr4-JT8YZ_5"
      },
      "source": [
        "question_code_pairs['code'] = question_code_pairs['code'].apply(lambda x: \"\".join(x))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-ulu10KYbye"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfk7mm9LYeFZ"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrR6Y-mvYx_v",
        "outputId": "54b2f60e-c60b-4dea-bb57-9ca3a8328ad6"
      },
      "source": [
        "question_code_pairs['code']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       num1 = 5465461\\nnum2 = 8765468\\nsum = num1 + n...\n",
              "1       def add_two_numbers(num1, num2):\\n\\tsum = num1...\n",
              "2       num1 = 123\\nnum2 = 125\\nnum3 = 148\\nif (num1 >...\n",
              "3       num1 = 100\\nnum2 = 200\\nnum3 = 300\\nif (num1 <...\n",
              "4        def merge_lists(l1, l2):\\n\\treturn l1 + l2\\n\\n\\n\n",
              "                              ...                        \n",
              "2130      a = 60\\nb = 13\\n\\nc = a | b\\nprint(\"OR\", c)\\n\\n\n",
              "2131     a = 60\\nb = 13\\n\\nc = a ^ b\\nprint(\"XOR\", c)\\n\\n\n",
              "2132    a = 60\\n\\nc = ~a\\nprint(\"Binary Ones Complemen...\n",
              "2133        c = a << 2\\nprint(\"Binary Left Shift\", c)\\n\\n\n",
              "2134         c = a >> 2\\nprint(\"Binary Right Shift\", c)\\n\n",
              "Name: code, Length: 2135, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6hZNpt2ZhWa"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ycQlglzlaHsV",
        "outputId": "933afc78-b1b3-44a1-9e59-74a5a4a462e8"
      },
      "source": [
        "question_code_pairs['code'][1]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def add_two_numbers(num1, num2):\\n\\tsum = num1 + num2\\n\\treturn sum\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf8W4FinaVuq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y99_SIGnY3gJ",
        "outputId": "da5bcf51-33ed-44d1-9a3c-c928bda2b720"
      },
      "source": [
        "# Test Tokenization\r\n",
        "s=question_code_pairs['code'][1]\r\n",
        "\r\n",
        "tokens = tokenize.tokenize(BytesIO(s.encode('utf-8')).readline)\r\n",
        "print([token.string for token in tokens])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['utf-8', 'def', 'add_two_numbers', '(', 'num1', ',', 'num2', ')', ':', '\\n', '\\t', 'sum', '=', 'num1', '+', 'num2', '\\n', 'return', 'sum', '\\n', '\\n', '\\n', '', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmp3ryrXYhnQ"
      },
      "source": [
        "def tokenize_en(text, max_length=200):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    tokens = [tok.text for tok in spacy_en.tokenizer(text)]\r\n",
        "    tokens = tokens[:max_input_length]\r\n",
        "    return "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnlMQA9PYoRL"
      },
      "source": [
        "def tokenize_py(text, max_length=200):\r\n",
        "  \"\"\"\r\n",
        "  Tokenizes Python code from a string into a list of strings\r\n",
        "  \"\"\"\r\n",
        "  tokens = tokenize.tokenize(BytesIO(text.encode('utf-8')).readline)\r\n",
        "  tokens = [token.string for token in tokens]\r\n",
        "  tokens = tokens[:max_input_length]\r\n",
        "  return tokens"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vGXTBGiYkTT"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "TRG = Field(tokenize = tokenize_py, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True\r\n",
        "            )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGub3FhkbAbz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}